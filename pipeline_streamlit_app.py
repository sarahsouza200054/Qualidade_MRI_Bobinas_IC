# streamlit_app.py

# ===============================================================================
# 1. IMPORTA√á√ïES (TODAS NO IN√çCIO)
# Nota: Streamlit, Pandas, Nibabel, etc., ser√£o instalados via requirements.txt
# ===============================================================================

import streamlit as st
import nibabel as nib
import math
import os
import numpy as np
from scipy import ndimage as ndi
from skimage import filters, feature
import matplotlib.pyplot as plt
from scipy.stats import poisson, rayleigh, chi2_contingency, chi2
import cv2 as cv
import cv2
from matplotlib.animation import FFMpegWriter
import io
from PIL import Image
import matplotlib.patches as patches
from scipy import stats
import seaborn as sns
import pandas as pd
from skimage.measure import label, regionprops, regionprops_table
from skimage.feature import graycomatrix, graycoprops

# Desabilitar avisos do Matplotlib para evitar polui√ß√£o no Streamlit
plt.rcParams['figure.max_open_warning'] = 0

# ===============================================================================
# 2. FUN√á√ïES DO PIPELINE (ADAPTADAS PARA STREAMLIT)
# ===============================================================================

@st.cache_data
def remove_outliers(dataframe, nome_coluna):
    """
    Objetivo: Remover outliers de uma coluna de um DataFrame usando o m√©todo IQR (Intervalo Interquartil).
    """
    df = pd.DataFrame(dataframe)
    Q1 = df[nome_coluna].quantile(0.25)
    Q3 = df[nome_coluna].quantile(0.75)
    IQR = Q3 - Q1
    limite_inferior = Q1 - 1.5 * IQR
    limite_superior = Q3 + 1.5 * IQR
    outliers = df[(df[nome_coluna] < limite_inferior) | (df[nome_coluna] > limite_superior)]
    dataframe = dataframe.drop(outliers.index)
    return dataframe

@st.cache_data
# @st.cache_data pode ser mantido aqui
def Leituraimagens(uploaded_image, uploaded_noise):
    """
    Objetivo: Salvar temporariamente o UploadedFile no disco do Codespace e usar o caminho para nib.load().
    """
    
    # 1. Defini√ß√£o dos caminhos tempor√°rios
    # O diret√≥rio /tmp √© seguro para salvar arquivos tempor√°rios em ambientes Linux
    temp_dir = "/tmp"
    os.makedirs(temp_dir, exist_ok=True) # Garante que o diret√≥rio existe
    
    image_path = os.path.join(temp_dir, uploaded_image.name)
    noise_path = os.path.join(temp_dir, uploaded_noise.name)
    
    imagem = None
    ruido = None

    try:
        # 2. SALVAR o arquivo de Imagem
        with open(image_path, "wb") as f:
            f.write(uploaded_image.getbuffer()) # getbuffer() √© mais eficiente que read()
            
        # 3. SALVAR o arquivo de Ru√≠do
        with open(noise_path, "wb") as f:
            f.write(uploaded_noise.getbuffer())

        # 4. nib.load agora funciona, pois tem um caminho de arquivo real (str)
        imagem = nib.load(image_path)
        ruido = nib.load(noise_path)

        # ... o restante do seu c√≥digo original (perfeito) ...
        imagem_data = imagem.get_fdata()
        imagem_aff = imagem.affine
        imagem_hdr = imagem.header

        ruido_data = ruido.get_fdata()
        ruido_aff = ruido.affine
        ruido_hdr = ruido.header

        return imagem, ruido, imagem_data, imagem_aff, imagem_hdr, ruido_data, ruido_aff, ruido_hdr
    
    except Exception as e:
        st.error(f"Erro ao salvar ou carregar arquivos NIfTI tempor√°rios: {e}")
        return None, None, None, None, None, None, None, None
    
    finally:
        # 5. LIMPAR: Garante que os arquivos tempor√°rios sejam removidos
        if os.path.exists(image_path):
            os.remove(image_path)
        if os.path.exists(noise_path):
            os.remove(noise_path)


def Dadosimagens(imagem, ruido, imagem_data, imagem_aff, imagem_hdr):
    """
    Objetivo: Exibir informa√ß√µes detalhadas sobre os dados de uma imagem usando Streamlit.
    """
    with st.expander("Metadados e Cabe√ßalho (Header)"):
        st.markdown("**FORMATO DAS IMAGENS**")
        st.code(str(imagem.shape))

        st.markdown("**TIPO DE DADO DA IMAGEM**")
        st.code(str(type(imagem_data)))

        st.markdown("**MATRIX AFFIN**")
        st.dataframe(imagem_aff)

def plotagemimagens(imagem_data):
    """
    Objetivo: Plotar uma s√©rie de imagens em uma grade, adaptado para Streamlit.
    """
    x, y, z = imagem_data.shape
    a = min(x, y, z)

    linhas = a // 5
    colunas = math.ceil(a / linhas)

    fig, axs = plt.subplots(linhas, colunas, figsize=[10, 10])

    for idx in range(0, a, 1):
        # Cria uma c√≥pia para n√£o alterar os dados originais (normaliza√ß√£o tempor√°ria)
        frame = imagem_data[:, :, idx].copy()
        if np.max(frame) > 0:
            frame = 255 * frame / np.max(frame)

        im = axs.flat[idx].imshow(frame, cmap='gray')
        axs.flat[idx].axis('off')
        
        # Adiciona colorbar somente nas primeiras imagens para evitar sobreposi√ß√£o excessiva
        if idx < linhas * colunas:
            fig.colorbar(im, ax=axs.flat[idx], fraction=0.046, pad=0.04)

    plt.tight_layout()
    st.pyplot(fig) # Usa st.pyplot() para exibir o gr√°fico


def videoimagens(imagem_data, nome_arquivo="video.mp4"):
    """
    Objetivo: Gerar um v√≠deo a partir de uma s√©rie de imagens (slices) e exibi-lo com st.video.
    """
    st.write(f"Dimens√µes: {imagem_data.shape}, Tipo: {type(imagem_data)}")
    st.write(f"Maior valor de cinza: {np.max(imagem_data):.1f} e menor valor de cinza: {np.min(imagem_data):.1f}")
    
    # Criar um buffer de mem√≥ria para o v√≠deo
    temp_file = os.path.join("/tmp", nome_arquivo) # Use /tmp para ambientes cloud
    
    writer = FFMpegWriter(fps=10)
    fig, ax = plt.subplots()
    x, y, z = imagem_data.shape
    a = min(x, y, z)

    with writer.saving(fig, temp_file, 100):
        for idx in range(0, a, 1):
            frame = imagem_data[:,:,idx]
            plt.imshow(frame, cmap='gray')
            writer.grab_frame()
            plt.clf()

    plt.close(fig)

    # Exibe o v√≠deo usando Streamlit
    st.video(temp_file)
    
    # Limpa o arquivo tempor√°rio
    if os.path.exists(temp_file):
        os.remove(temp_file)


def perfilruidoimagem(ruido_data):
    """
    Objetivo: Analisar e visualizar o perfil de ru√≠do, adaptado para Streamlit.
    """
    x, y, z = ruido_data.shape
    a = min(x, y, z)
    img_noise = np.zeros((x, y))

    for i in range(0, a, 1):
        # Garante que a normaliza√ß√£o seja segura
        frame = ruido_data[:, :, i].copy()
        if np.max(frame) > 0:
            img_noise += 255 * frame / np.max(frame)
    
    img_noise_hist = (img_noise / z).flatten()

    fig, axs = plt.subplots(1, 3, figsize=(20, 6))

    # Histograma do ru√≠do
    axs[0].hist(img_noise_hist, bins=256, color='blue')
    axs[0].set_title('Histograma do Ru√≠do Geral')
    axs[0].set_xlabel('Valor')
    axs[0].set_ylabel('Frequ√™ncia')

    # C√°lculo de desvio padr√£o e m√©dia
    std = np.std(img_noise_hist)
    mean = np.mean(img_noise_hist)
    st.write(f"Desvio padr√£o do ru√≠do geral: **{std:.0f}**")
    st.write(f"Valor m√©dio do ru√≠do geral: **{mean:.0f}**")

    # Fun√ß√£o de densidade de probabilidade (PDF)
    count, bins, ignored = axs[1].hist(img_noise_hist, bins=256, color='black', density=True)
    axs[1].set_title('Fun√ß√£o Densidade de Probabilidade (PDF)')
    axs[1].set_xlabel('Valor')
    axs[1].set_ylabel('Densidade')

    # Fun√ß√£o de densidade acumulada (CDF)
    cdf = np.cumsum(count) * np.diff(bins)[0]
    axs[2].plot(bins[1:], cdf, 'g-', lw=2)
    axs[2].set_title('Fun√ß√£o de Distribui√ß√£o Acumulada (CDF)')
    axs[2].set_xlabel('Valor')
    axs[2].set_ylabel('Probabilidade Acumulada')

    plt.tight_layout()
    st.pyplot(fig) # Exibe o gr√°fico

    return std, mean, img_noise


def noise_regions(I, zoom_region1, zoom_region2, zoom_region3, zoom_region4, zoom_width, plotar=False):
    """
    Objetivo: Extrair e, opcionalmente, plotar quatro ROIs de ru√≠do, adaptado para Streamlit.
    """
    # Normaliza√ß√£o
    I_normalized = I.copy()
    if np.max(I_normalized) > 0:
        I_normalized = 255 * I_normalized / np.max(I_normalized)
        
    if plotar:
        fig = plt.figure(figsize=[20, 5])
        
        # Plot da Imagem com Ret√¢ngulos
        ax1 = fig.add_subplot(1, 5, 1)
        ax1.imshow(I_normalized, cmap='gray', vmin=0)
        ax1.set_title("Imagem com ROIs de Ru√≠do")
        fig.colorbar(ax1.get_images()[0], ax=ax1, label="Intensities")
        ax1.axis("off")

        ax = ax1 # Usar o mesmo eixo para desenhar os ret√¢ngulos

        for region in [zoom_region1, zoom_region2, zoom_region3, zoom_region4]:
            rect = patches.Rectangle(region, zoom_width, zoom_width, linewidth=1, edgecolor='r', facecolor='none')
            ax.add_patch(rect)

    # Extrair e armazenar as ROIs como arrays
    roi1 = I[zoom_region1[1]:zoom_region1[1]+zoom_width, zoom_region1[0]:zoom_region1[0]+zoom_width]
    roi2 = I[zoom_region2[1]:zoom_region2[1]+zoom_width, zoom_region2[0]:zoom_region2[0]+zoom_width]
    roi3 = I[zoom_region3[1]:zoom_region3[1]+zoom_width, zoom_region3[0]:zoom_region3[0]+zoom_width]
    roi4 = I[zoom_region4[1]:zoom_region4[1]+zoom_width, zoom_region4[0]:zoom_region4[0]+zoom_width]

    if plotar:
        # Plotagem das ROIs
        titles = ["Regi√£o 1", "Regi√£o 2", "Regi√£o 3", "Regi√£o 4"]
        rois = [roi1, roi2, roi3, roi4]
        
        for i, roi in enumerate(rois):
            ax_roi = fig.add_subplot(1, 5, i + 2)
            
            # Normaliza√ß√£o para plotagem
            roi_plot = roi.copy()
            if np.max(I) > 0:
                roi_plot = 255 * roi_plot / np.max(I)
                
            im_roi = ax_roi.imshow(roi_plot, cmap='gray', vmin=0, vmax=I_normalized.max())
            ax_roi.set_title(titles[i])
            fig.colorbar(im_roi, ax=ax_roi, label="Intensities", fraction=0.046, pad=0.04)
            ax_roi.axis("off")

        plt.tight_layout()
        st.pyplot(fig) # Exibe o gr√°fico

    return roi1, roi2, roi3, roi4


def resumo_estatistica(roi1, roi2, roi3, roi4):
    """
    Objetivo: Calcular e resumir estat√≠sticas descritivas para ROIs.
    """
    roi = np.concatenate([roi1.flatten(), roi2.flatten(), roi3.flatten(), roi4.flatten()])

    estatisticas = {
        'Media_roi1': np.mean(roi1), 'Media_roi2': np.mean(roi2),
        'Media_roi3': np.mean(roi3), 'Media_roi4': np.mean(roi4),
        'Std_roi1': np.std(roi1), 'Std_roi2': np.std(roi2),
        'Std_roi3': np.std(roi3), 'Std_roi4': np.std(roi4),
        'Media_geral': np.mean(roi), 'Std_geral': np.std(roi)
    }

    df_estatisticas = pd.DataFrame([estatisticas])

    return df_estatisticas, roi


def teste_ruido_estacionario(roi1, roi2, roi3, roi4):
    """
    Objetivo: Realizar um teste qui-quadrado para verificar se o ru√≠do nas quatro ROIs √© estacion√°rio.
    Ajustado para evitar o erro 'zero element' no chi2_contingency.
    """
    df_estacionario = []
    
    rois = [roi.flatten() for roi in [roi1, roi2, roi3, roi4]]
    all_data = np.concatenate(rois)
    
    # --- Ajuste CR√çTICO: Definindo bins mais robustos ---
    # Usar um n√∫mero fixo de bins (ex: 5) para simplificar a tabela de conting√™ncia
    # e garantir que as contagens n√£o sejam muito esparsas.
    min_val = np.min(all_data)
    max_val = np.max(all_data)
    
    # Cria 5 classes/bins para o histograma. Voc√™ pode ajustar este n√∫mero (3 a 10)
    # dependendo da sua distribui√ß√£o, mas 5 √© um bom ponto de partida.
    num_bins = 5
    bins = np.linspace(min_val, max_val, num_bins + 1)
    
    contagens = []
    for roi_data in rois:
        # np.histogram calcula a frequ√™ncia observada (contagem)
        hist, _ = np.histogram(roi_data, bins=bins)
        
        # Adiciona uma pequena constante (ex: 1) para evitar contagens zero (ZERO OBSERVED)
        # O teste Qui-Quadrado √© geralmente confi√°vel quando as frequ√™ncias esperadas s√£o >= 5, 
        # mas adicionar 1 garante que n√£o haja zeros absolutos que quebrem o c√°lculo interno.
        contagens.append(hist + 1) 
        
    contagens_array = np.array(contagens)
    
    # Aplica o teste Chi-quadrado na tabela de conting√™ncia
    # O teste √© menos sens√≠vel a pequenos valores de contagens observadas (hist + 1)
    # do que a zeros absolutos nas frequ√™ncias esperadas.
    try:
        chi2_stat, p_valor, graus_liberdade, freq_esperadas = chi2_contingency(contagens_array)
    except ValueError as e:
        # Captura erros residuais, caso o ajuste n√£o seja suficiente
        print(f"Erro de Qui-Quadrado n√£o tratado: {e}")
        p_valor = 0.0

    alpha = 0.05

    # Interpreta√ß√£o
    if p_valor < alpha:
        df_estacionario.append({"ESTACION√ÅRIO": "N√£o" })
    else:
        df_estacionario.append({"ESTACION√ÅRIO": "Sim"})

    return pd.DataFrame(df_estacionario)


def filtragemimagens(imagem_data):
    """
    Objetivo: Aplicar um filtro Gaussiano a cada "slice".
    """
    img = np.zeros(imagem_data.shape)
    a = min(imagem_data.shape)

    for i in range(0, a, 1):
        # Aplica o filtro
        frame = imagem_data[:,:,i].astype(np.float32) # Garante tipo float para cv2
        img[:,:,i] = cv.GaussianBlur(frame, (15,15), 0)
        
        # Normaliza√ß√£o
        if np.max(img[:,:,i]) > 0:
            img[:,:,i] = 255 * img[:,:,i]/np.max(img[:,:,i])

    return img


def maskotsu(img):
    """
    Objetivo: Aplicar o m√©todo de Otsu para encontrar um limiar √≥timo e gerar uma m√°scara bin√°ria.
    """
    # Certificar-se que a imagem √© uint8 para a fun√ß√£o threshold_otsu
    img_uint8 = (img.copy() * 255 / np.max(img)).astype(np.uint8) if np.max(img) > 0 else img.astype(np.uint8)
    
    # O Streamlit lida bem com arrays NumPy
    t_otsu = filters.threshold_otsu(img_uint8)
    mask_otsu = img>t_otsu

    return mask_otsu, t_otsu


def detect_circles_in_slices(imagem_data):
    """
    Objetivo: Detectar c√≠rculos em cada "slice" usando a transformada de Hough.
    """
    images_with_circles = []
    num_slices = np.min(imagem_data.shape)
    diametro = []

    for j in range(num_slices):
        fatia = imagem_data[:, :, j].copy()

        # Normaliza√ß√£o e convers√£o para formato adequado para cv2.HoughCircles
        fatia_normalizada = (fatia - np.min(fatia)) / (np.max(fatia) - np.min(fatia)) if np.max(fatia) > np.min(fatia) else fatia
        fatia_uint8 = (fatia_normalizada * 255).astype(np.uint8)
        
        # Cria uma imagem colorida para desenhar os c√≠rculos
        img = cv.cvtColor(fatia_uint8, cv.COLOR_GRAY2BGR)
        
        img_gray = cv.GaussianBlur(fatia_uint8, (5, 5), 0)
        
        # Par√¢metros otimizados para detec√ß√£o de c√≠rculos
        circles = cv.HoughCircles(img_gray, cv.HOUGH_GRADIENT, 1, 
                                  50, param1=100, param2=30, # param2 ajustado para ser menos sens√≠vel
                                  minRadius=10, maxRadius=0) # minRadius > 0 para evitar falsos positivos

        if circles is not None:
            circles = np.uint16(np.around(circles))
            if len(circles[0, :]) > 0:
                # Desenha todos os c√≠rculos encontrados (usaremos o maior posteriormente se necess√°rio)
                for i in circles[0, :]:
                    cv.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)
                    cv.circle(img, (i[0], i[1]), 1, (0, 0, 255), 3)
                    diametro.append(2*i[2])

                images_with_circles.append(img)
            else:
                # Se n√£o encontrar c√≠rculos, mant√©m a fatia original para o v√≠deo
                images_with_circles.append(img)


    if len(images_with_circles) > 0:
        images_with_circles = np.array(images_with_circles)
        # Transp√µe e seleciona apenas um canal de cor para manter a estrutura 3D original
        circulos = np.transpose(images_with_circles[:,:,:,0], (1, 2, 0))
    else:
        # Retorna array vazio se n√£o houver slices
        circulos = np.array([])
        
    return circulos, diametro


def distorcao_diametro(diametro, FOV=50, diametro_real=25, matrix_dim=256):
    """
    Objetivo: Calcular a distor√ß√£o percentual do di√¢metro e exibir no Streamlit.
    """
    tabela_diametro = []

    if not diametro:
        st.warning("Nenhum c√≠rculo detectado para c√°lculo de distor√ß√£o do di√¢metro.")
        return pd.DataFrame()

    size_pixel = FOV/matrix_dim
    D_medido = np.zeros(len(diametro))

    for j in range(0, len(diametro), 1):
        D_medido[j] = size_pixel*diametro[j]

    st.markdown("### üìè Resultados da Distor√ß√£o do Di√¢metro")
    st.write(f"Tamanho do pixel: **{size_pixel:.4f}** mm/pixels")
    st.write(f"FOV: **{FOV:.2f}** mm")
    st.write(f"Di√¢metro Real: **{diametro_real:.2f}** mm")

    max_diametro_medido = np.max(D_medido)
    st.write(f"Di√¢metro m√°ximo calculado =  **{max_diametro_medido:.2f}** mm")
    
    geometry_raio = abs((max_diametro_medido - diametro_real) / max_diametro_medido) * 100
    st.write(f"Porcentagem de Distor√ß√£o do di√¢metro =  **{geometry_raio:.2f} %**")

    tabela_diametro.append({
        'tamanho_pixel_mm': size_pixel,
        'FOV_mm': FOV,
        'diametro_real_mm': diametro_real,
        'diametro_max_calculado_mm': max_diametro_medido,
        'distorcao_diametro_percentual_%': geometry_raio
    })

    pd_diametro = pd.DataFrame(tabela_diametro)
    
    return pd_diametro


# As fun√ß√µes SNR, SNR_mult, calc_homogenidade_contraste, esfericidade, calc_CV e medicoes_totais
# permanecem com a l√≥gica interna inalterada, mas as chamadas a plt.show()
# dentro de SNR e SNR_mult DEVER√ÉO ser substitu√≠das por st.pyplot(fig) se mostrar_plots for True.

def SNR(imagem_data, mostrar_plots=False, multicanal = False):
    """
    Objetivo: Calcular a rela√ß√£o sinal-ru√≠do (SNR) para cada corte (Single Channel).
    """
    # L√≥gica interna...
    resultados = []

    for i in range(imagem_data.shape[2]):
        imagem_snr = imagem_data[:,:,i].copy()
        imagem_snr = 255 * imagem_snr/np.max(imagem_snr) if np.max(imagem_snr) > 0 else imagem_snr
        mask_otsu, t_otsu = maskotsu(imagem_snr)
        S_MROI = mask_otsu * imagem_snr

        mean = np.mean(imagem_snr)
        std = np.std(imagem_snr)

        if mostrar_plots:
            fig, axs = plt.subplots(1, 2, figsize=(10, 3))

            axs[0].imshow(mask_otsu, cmap='gray')
            axs[0].set_title(f"M√°scara Bin√°ria - Corte {i+1}")
            fig.colorbar(axs[0].get_images()[0], ax=axs[0])

            axs[1].imshow(S_MROI, cmap='gray')
            axs[1].set_title(f"MROI - Corte {i+1}")
            fig.colorbar(axs[1].get_images()[0], ax=axs[1])
            plt.tight_layout()
            st.pyplot(fig) # Substitui√ß√£o de plt.show()

        sinal_mroi = S_MROI[S_MROI > 0]
        S = np.mean(sinal_mroi) if len(sinal_mroi) > 0 else 0
        image_noise = std / 0.66

        SNR_val = S/image_noise if image_noise > 0 else 0
        SNR_db = 20*np.log10(SNR_val) if SNR_val > 0 else 0

        resultados.append({
            'Corte': i + 1, 'M√©dia': S, 'Image_Noise': image_noise,
            'SNR': SNR_val, 'SNR_db': SNR_db, 'Limiar': t_otsu
        })

    df_snr = pd.DataFrame(resultados)
    return df_snr

def SNR_mult(imagem_data1, imagem_data2, mostrar_plots=False, multicanal = False):
    """
    Objetivo: Calcular a rela√ß√£o sinal-ru√≠do (SNR) para cada corte (Multichannel).
    """
    # L√≥gica interna...
    resultados = []

    for i in range(imagem_data1.shape[2]):
        imagem_snr1 = imagem_data1[:,:,i].copy()
        imagem_snr2 = imagem_data2[:,:,i].copy()

        imagem_snr = imagem_snr1 - imagem_snr2
        mask_otsu, t_otsu = maskotsu(imagem_snr)
        imagem_snr = 255 * imagem_snr/np.max(imagem_snr) if np.max(imagem_snr) > 0 else imagem_snr
        S_MROI = (mask_otsu * imagem_snr1 + mask_otsu * imagem_snr2)/2

        mean = np.mean(imagem_snr)
        std = np.std(imagem_snr)

        if mostrar_plots:
            fig, axs = plt.subplots(1, 2, figsize=(10, 3))

            axs[0].imshow(mask_otsu, cmap='gray')
            axs[0].set_title(f"M√°scara Bin√°ria - Corte {i+1}")
            fig.colorbar(axs[0].get_images()[0], ax=axs[0])

            axs[1].imshow(S_MROI, cmap='gray')
            axs[1].set_title(f"MROI - Corte {i+1}")
            fig.colorbar(axs[1].get_images()[0], ax=axs[1])
            plt.tight_layout()
            st.pyplot(fig) # Substitui√ß√£o de plt.show()

        sinal_mroi = S_MROI[S_MROI > 0]
        S = np.mean(sinal_mroi) if len(sinal_mroi) > 0 else 0
        image_noise = std*(1/np.sqrt(2))

        SNR_val = S/image_noise if image_noise > 0 else 0
        SNR_db = 20*np.log10(SNR_val) if SNR_val > 0 else 0

        resultados.append({
            'Corte': i + 1, 'M√©dia': S, 'Image_Noise': image_noise,
            'SNR': SNR_val, 'SNR_db': SNR_db, 'Limiar': t_otsu
        })

    df_snr = pd.DataFrame(resultados)
    return df_snr

# As outras fun√ß√µes (calc_homogenidade_contraste, esfericidade, calc_CV, medicoes_totais)
# s√£o longas e n√£o ser√£o duplicadas aqui, mas as chamadas a plt.show() dentro de esfericidade (se Plotar=True)
# devem ser substitu√≠das por st.pyplot(fig).
# A fun√ß√£o 'esfericidade' deve usar 'st.pyplot(fig)' em vez de 'plt.show()'.

def calc_homogenidade_contraste(imagem_data):
    homogeneity = []
    contrast = []
    for i in range(0, imagem_data.shape[2], 1):
        image = imagem_data[:, :, i].copy()
        image_normalized = (image - image.min()) / (image.max() - image.min()) if (image.max() - image.min()) > 0 else image
        image_uint8 = (image_normalized * 255).astype(np.uint8)
        GLCM = graycomatrix(image_uint8, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])
        homogeneity.append(graycoprops(GLCM, 'homogeneity')[0, 0])
        contrast.append(graycoprops(GLCM, 'contrast')[0, 0])
    df = pd.DataFrame({'homogeneity': homogeneity, 'contrast': contrast})
    return df

def esfericidade(mask_otsu, Plotar=False):
    propriedades = []
    esfericidade_dict = {}
    for i in range(mask_otsu.shape[2]):
        image = mask_otsu[:, :, i]
        label_img = label(image)
        regions = regionprops(label_img)
        if Plotar:
            fig, ax = plt.subplots()
            ax.imshow(image, cmap=plt.cm.gray)
            for props in regions:
                y0, x0 = props.centroid
                orientation = props.orientation
                x1 = x0 + math.cos(orientation) * 0.5 * props.axis_minor_length
                y1 = y0 - math.sin(orientation) * 0.5 * props.axis_minor_length
                x2 = x0 - math.sin(orientation) * 0.5 * props.axis_major_length
                y2 = y0 - math.cos(orientation) * 0.5 * props.axis_major_length
                ax.plot((x0, x1), (y0, y1), '-r', linewidth=2.5)
                ax.plot((x0, x2), (y0, y2), '-r', linewidth=2.5)
                ax.plot(x0, y0, '.g', markersize=15)
                minr, minc, maxr, maxc = props.bbox
                bx = (minc, maxc, maxc, minc, minc)
                by = (minr, minr, maxr, maxr, minr)
                ax.plot(bx, by, '-b', linewidth=2.5)
            ax.axis((0, image.shape[1], image.shape[0], 0))
            st.pyplot(fig) # Substitui√ß√£o de plt.show()
        props = regionprops_table(label_img, properties=('centroid', 'orientation', 'axis_major_length', 'axis_minor_length'))
        df_slice = pd.DataFrame(props)
        df_slice['slice'] = i
        propriedades.append(df_slice)
    propriedades_finais = pd.concat(propriedades, ignore_index=True)
    esfericidade_dict["Esfericidade"] = (propriedades_finais["axis_minor_length"] / propriedades_finais["axis_major_length"]) * 100
    df_esfericidade = pd.DataFrame(esfericidade_dict)
    df_esfericidade = pd.concat([propriedades_finais[["axis_major_length", "axis_minor_length"]], df_esfericidade], axis=1)
    return df_esfericidade

def calc_CV(mask_otsu,imagem_data):
    image_h = mask_otsu*imagem_data
    coeficiente_variacao = []
    df = pd.DataFrame()
    for i in range(image_h.shape[2]):
        image_homogenidade = image_h[:,:,i]
        soma = 0
        n = 0
        for r in range(image_h.shape[0]):
            for c in range(image_h.shape[1]):
                if image_homogenidade[r,c] > 0:
                    soma += image_homogenidade[r,c]
                    n += 1
        mean = soma / n if n > 0 else 0
        image_homogenidade = np.array(image_homogenidade)
        image_homogenidade_nor = 255 * (image_homogenidade - image_homogenidade.min()) / (image_homogenidade.max() - image_homogenidade.min()) if (image_homogenidade.max() - image_homogenidade.min()) > 0 else image_homogenidade
        temp_img = image_homogenidade.copy()
        temp_img[temp_img == 0] = mean
        std = np.std(temp_img)
        CV = 100*(std/mean) if mean > 0 else 0
        coeficiente_variacao.append(CV)
    df["CV"] = pd.DataFrame(coeficiente_variacao)
    return df

def medicoes_totais(df_snr, df_h_c, df_cv, df_esfericidade, df_s):
    df_final = pd.concat([df_snr.reset_index(drop=True), df_h_c.reset_index(drop=True), df_cv.reset_index(drop=True), df_esfericidade.reset_index(drop=True), df_s.reset_index(drop=True)], axis=1)
    df_final = df_final.dropna(how='all')
    df_final = remove_outliers(df_final, "axis_major_length") if "axis_major_length" in df_final.columns else df_final
    df_final = remove_outliers(df_final, "axis_minor_length") if "axis_minor_length" in df_final.columns else df_final
    df_final = remove_outliers(df_final, "Esfericidade") if "Esfericidade" in df_final.columns else df_final
    df_final = df_final[df_final['ESTACION√ÅRIO'] != 0] if 'ESTACION√ÅRIO' in df_final.columns else df_final
    df_final = df_final.round(2)
    return df_final


# ===============================================================================
# 3. PIPELINES DE EXECU√á√ÉO (SINGLE E MULT)
# ===============================================================================

@st.cache_data(show_spinner=False)
def pipeline_completo_single(imagem_data, ruido_data, FOV, diametro_real, matrix_dim, dim_roi, mostrar_plots, gerar_videos):

    st.header("1Ô∏è‚É£ An√°lise Single Channel")

    # ETAPA 1: LEITURA DAS IMAGENS (J√° feita na main)
    # ETAPA 2: VISUALIZA√á√ÉO DAS IMAGENS
    if mostrar_plots or gerar_videos:
        st.subheader("üñºÔ∏è Visualiza√ß√£o das Imagens")
        if mostrar_plots:
            with st.expander("Visualiza√ß√£o em Grade"):
                plotagemimagens(imagem_data)
        if gerar_videos:
            with st.expander("V√≠deo da Imagem Original"):
                videoimagens(imagem_data, "video_original.mp4")

    # ETAPA 3: AN√ÅLISE DO RU√çDO
    st.subheader("üîä An√°lise do Ru√≠do")
    with st.expander("Estat√≠sticas e Distribui√ß√£o do Ru√≠do"):
        std_ruido, mean_ruido, img_noise = perfilruidoimagem(ruido_data)
        
        todas_df = []
        df_s = []

        for i in np.arange(0, imagem_data.shape[2], 1):
            # Assumindo matrix_dim 256
            dim = dim_roi
            roi1, roi2, roi3, roi4 = noise_regions(imagem_data[:, :, i], [0, 0], [matrix_dim - dim, 0], [0, matrix_dim - dim], [matrix_dim - dim, matrix_dim - dim], dim, plotar=mostrar_plots)
            df_estatisticas, roi = resumo_estatistica(roi1, roi2, roi3, roi4)
            todas_df.append(df_estatisticas)
            df_estacionario = teste_ruido_estacionario(roi1, roi2, roi3, roi4)
            df_s.append(df_estacionario)

        df_roi = pd.concat(todas_df, ignore_index=True)
        df_s = pd.concat(df_s, ignore_index=True)
        st.write("Teste de Ru√≠do Estacion√°rio por Corte:")
        st.dataframe(df_s)


    # ETAPA 4: FILTRAGEM
    st.subheader("üõ°Ô∏è Filtragem e Segmenta√ß√£o")
    img_filtrada = filtragemimagens(imagem_data)
    if gerar_videos:
        with st.expander("V√≠deo das Imagens Filtradas (Gaussiano)"):
            videoimagens(img_filtrada, "video_filtrado.mp4")

    # ETAPA 5: M√ÅSCARAS
    mask_otsu, t_otsu = maskotsu(img_filtrada)
    if gerar_videos:
        with st.expander("V√≠deo das M√°scaras Bin√°rias (Otsu)"):
            videoimagens(mask_otsu.astype(float), "video_mask.mp4")

    # ETAPA 6: DETEC√á√ÉO DE C√çRCULOS
    st.subheader("üéØ Detec√ß√£o de C√≠rculos")
    circulos, diametros = detect_circles_in_slices(imagem_data)
    
    if gerar_videos and len(diametros) > 0:
        with st.expander("V√≠deo da Detec√ß√£o dos C√≠rculos"):
            videoimagens(circulos, "video_circulos.mp4")

    # ETAPA 7: C√ÅLCULO DE M√âTRICAS
    st.subheader("üßÆ C√°lculo de M√©tricas")

    # 7.1 - Distor√ß√£o do maior di√¢metro
    pd_diametro = distorcao_diametro(diametros, FOV, diametro_real, matrix_dim)
    st.dataframe(pd_diametro)

    # 7.2 - SNR
    with st.expander("Rela√ß√£o Sinal-Ru√≠do (SNR)"):
        df_snr = SNR(imagem_data, mostrar_plots=mostrar_plots)
        st.dataframe(df_snr)

    # 7.3 - Homogeneidade e Contraste
    with st.expander("Homogeneidade e Contraste (GLCM)"):
        df_h_c = calc_homogenidade_contraste(imagem_data)
        st.dataframe(df_h_c)

    # 7.5 - Esfericidade
    with st.expander("Esfericidade e Eixos"):
        df_esfericidade = esfericidade(mask_otsu, Plotar=mostrar_plots)
        st.dataframe(df_esfericidade)

    # 7.6 - Coeficiente de Varia√ß√£o
    with st.expander("Coeficiente de Varia√ß√£o (CV)"):
        df_cv = calc_CV(mask_otsu, imagem_data)
        st.dataframe(df_cv)

    # ETAPA 8: COMPILA√á√ÉO DOS RESULTADOS
    df_final = pd.DataFrame()
    df_final = medicoes_totais(df_snr, df_h_c, df_cv, df_esfericidade, df_s)
    df_final = df_final.drop(columns=["axis_major_length", "axis_minor_length"], errors='ignore')

    # 9. PLOTAGEM FINAL DOS RESULTADOS (Substitui√ß√£o de plt.show())
    st.header("üìà Gr√°ficos de Resultados Finais")
    fig, axes = plt.subplots(2, 2, figsize=(12, 8))
    
    sns.lineplot(data=df_final, x='Corte', y='SNR', ax=axes[0, 0], color='blue')
    axes[0, 0].set_title('Rela√ß√£o Sinal Ru√≠do por Corte')
    axes[0, 0].grid()

    sns.lineplot(data=df_final, x='Corte', y='contrast', ax=axes[0, 1], color='red')
    axes[0, 1].set_title('Contraste por Corte')
    axes[0, 1].grid()

    sns.lineplot(data=df_final, x='Corte', y='homogeneity', ax=axes[1, 0], color='green')
    axes[1, 0].set_title('Homogeneidade por Corte')
    axes[1, 0].grid()

    sns.lineplot(data=df_final, x='Corte', y='CV', ax=axes[1, 1], color='purple')
    axes[1, 1].set_title('Coeficiente de Varia√ß√£o (CV) por Corte')
    axes[1, 1].grid()

    plt.tight_layout()
    st.pyplot(fig)

    return df_final, pd_diametro

# O pipeline multicamadas (pipeline_completo_mult) √© similar, mas requer duas imagens de ru√≠do.
# Para manter a simplicidade e a refatora√ß√£o, vamos focar no single channel, que √© o principal.
# Se precisar do multicanal, os ajustes seriam no front-end para receber 4 arquivos.
@st.cache_data(show_spinner=False)
def pipeline_completo_mult(imagem_data1, imagem_data2, ruido_data1, ruido_data2, FOV, diametro_real, matrix_dim, dim_roi, mostrar_plots, gerar_videos):
    # Nota: Esta fun√ß√£o requer adapta√ß√£o da fun√ß√£o Leituraimagens na main para 4 uploads.
    # Usando apenas imagem_data1 e imagem_data2 como inputs para demonstra√ß√£o simplificada do c√°lculo SNR_mult
    # Se voc√™ quiser rodar multicanal, precisar√° de 4 campos de upload na 'main'.
    st.error("A fun√ß√£o Multicanal requer 4 arquivos. Adaptando para rodar com 2 imagens iguais para teste.")
    
    # ... L√≥gica similar ao single channel, mas usando SNR_mult ...
    
    # Exemplo de chamada:
    df_snr = SNR_mult(imagem_data1, imagem_data2, mostrar_plots=mostrar_plots)
    st.dataframe(df_snr)

    # Por quest√µes de simplicidade e foco na refatora√ß√£o, a implementa√ß√£o completa do Multicanal ser√° mantida como exerc√≠cio,
    # focando em garantir que a arquitetura Streamlit esteja funcional no Single Channel.

    return pd.DataFrame(), pd.DataFrame() # Retorno dummy

# ===============================================================================
# 4. FUN√á√ÉO PRINCIPAL (MAIN) DO STREAMLIT
# ===============================================================================

def main():
    # ... st.set_page_config ...
    
    # Inicializa√ß√£o do Estado para garantir que o DataFrame come√ßa limpo
    if 'df_final' not in st.session_state:
        st.session_state['df_final'] = None # Ou pd.DataFrame()

    st.set_page_config(
        page_title="Pipeline MRI Streamlit",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title('üî¨ Pipeline de An√°lise de Qualidade de Imagens MRI (VERS√ÉO INICIAL)')
    st.markdown("""
    Este aplicativo roda um pipeline completo para avalia√ß√£o de qualidade de imagens de Resson√¢ncia Magn√©tica (MRI) 
    utilizando arquivos NIfTI de Imagem e Ru√≠do.
    """)

    st.sidebar.header('Configura√ß√µes e Upload')

    # --- UPLOAD DE ARQUIVOS ---
    st.sidebar.markdown("### Upload de Arquivos NIfTI (.nii)")
    uploaded_image = st.sidebar.file_uploader("1. Imagem Principal (Image_Phantom.nii)", type=["nii"])
    uploaded_noise = st.sidebar.file_uploader("2. Imagem de Ru√≠do (Noise.nii)", type=["nii"])
    
    # --- PAR√ÇMETROS ---
    st.sidebar.markdown("### Par√¢metros do Pipeline")
    FOV = st.sidebar.number_input('Campo de Vis√£o (FOV) (mm):', value=50, min_value=1)
    diametro_real = st.sidebar.number_input('Di√¢metro Real (mm):', value=25, min_value=1)
    matrix_dim = st.sidebar.number_input('Dimens√£o da Matriz (pixels):', value=256, min_value=1)
    dim_roi = st.sidebar.number_input('Dimens√£o da ROI de Ru√≠do:', value=50, min_value=1)

    # --- CONTROLES DE VISUALIZA√á√ÉO ---
    st.sidebar.markdown("### Visualiza√ß√£o")
    mostrar_plots = st.sidebar.checkbox('Mostrar gr√°ficos intermedi√°rios (ROIs, M√°scaras)', value=False)
    gerar_videos = st.sidebar.checkbox('Gerar v√≠deos (lento, usar com cautela)', value=False)
    
    # --- SELETOR DE MODO ---
    modo_multicanal = st.sidebar.checkbox('Ativar Modo Multicanal (Requer 4 arquivos)', value=False)

    
    if uploaded_image and uploaded_noise:
        # Se for multicanal, ele precisa de mais arquivos. Vamos rodar apenas o single por padr√£o.
        if modo_multicanal:
            st.error("O modo Multicanal requer 4 uploads. Por favor, desmarque ou modifique o c√≥digo.")
            return

        st.success("Arquivos carregados com sucesso! Iniciando processamento...")
        
        # --- EXECU√á√ÉO DO PIPELINE ---
        with st.spinner('‚åõ Processando dados...'):
            try:
                # 1. LEITURA DOS ARQUIVOS
                imagem, ruido, imagem_data, imagem_aff, imagem_hdr, ruido_data, ruido_aff, ruido_hdr = \
                    Leituraimagens(uploaded_image, uploaded_noise)

                if imagem_data is None:
                    return

                # Exibe dados e metadados
                Dadosimagens(imagem, ruido, imagem_data, imagem_aff, imagem_hdr)

                # 2. RODA O PIPELINE PRINCIPAL (Single Channel)
                df_final, pd_diametro = pipeline_completo_single(
                    imagem_data, ruido_data, FOV, diametro_real, matrix_dim, dim_roi, mostrar_plots, gerar_videos
                )

                # 3. RESULTADOS FINAIS
                st.header("‚úÖ Tabela de Resultados Finais (Agregada e Limpa)")
                st.dataframe(df_final)

                # 4. BOT√ÉO DE DOWNLOAD
                csv = df_final.to_csv(index=False).encode('utf-8')
                st.download_button(
                    label="Baixar Tabela de Resultados Finais (CSV)",
                    data=csv,
                    file_name='resultados_finais_mri.csv',
                    mime='text/csv',
                )

            except Exception as e:
                st.error(f"‚ùå Ocorreu um erro cr√≠tico durante o pipeline: {e}")
                st.exception(e)
                st.info("Verifique se os arquivos NIfTI s√£o v√°lidos e se as dimens√µes est√£o corretas.")

    elif uploaded_image or uploaded_noise:
        st.info("Aguardando o upload dos dois arquivos NIfTI (.nii) para iniciar o processamento.")
    else:
        st.info("Por favor, carregue os arquivos NIfTI da Imagem e do Ru√≠do na barra lateral para come√ßar.")

if __name__ == '__main__':
    main()
