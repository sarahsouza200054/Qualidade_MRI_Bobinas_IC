# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1RLN2ek-Dj3KKFPG35P_h640-Xy12jDGN
"""

#PRIMEIRA ETAPA: BIBLIOTECA, DADOS E VISUALIZAÇÃO

#-------------------------------------------------------------------------------
#IMPORTAR AS BIBLIOTECAS
#-------------------------------------------------------------------------------

!pip install PyDrive
!pip install nibabel

from google.colab import drive
import nibabel as nib
drive.mount('/content/drive')

import math
import os
import numpy as np
from nibabel.testing import data_path
example_filename = os.path.join(data_path, 'example4d.nii.gz')
from scipy import ndimage as ndi
from skimage import filters, feature
import matplotlib.pyplot as plt
from scipy.stats import poisson
import cv2 as cv
import cv2
from matplotlib.animation import FFMpegWriter
from IPython.display import Video
from scipy.stats import poisson
import io
from PIL import Image
from scipy.stats import poisson
import matplotlib.patches as patches
from scipy import stats
import seaborn as sns
import pandas as pd
from scipy.stats import rayleigh

#-------------------------------------------------------------------------------
#FUNÇÃO QUE REMOVE OUTLIERS DOS DADOS
#-------------------------------------------------------------------------------

def remove_outliers(dataframe, nome_coluna):
    """
    Objetivo: Remover outliers de uma coluna de um DataFrame usando o método IQR (Intervalo Interquartil).

    Entrada:
        - dataframe (pd.DataFrame): O DataFrame a ser processado.
        - nome_coluna (str): O nome da coluna onde os outliers serão removidos.

    Saída:
        - dataframe (pd.DataFrame): O DataFrame original sem as linhas que contêm outliers na coluna especificada.
    """

    df = pd.DataFrame(dataframe)

    # Cálculo do IQR
    Q1 = df[nome_coluna].quantile(0.25)
    Q3 = df[nome_coluna].quantile(0.75)
    IQR = Q3 - Q1

    # Limites para detectar outliers
    limite_inferior = Q1 - 1.5 * IQR
    limite_superior = Q3 + 1.5 * IQR

    # Identificar outliers
    outliers = df[(df[nome_coluna] < limite_inferior) | (df[nome_coluna] > limite_superior)]
    dataframe = dataframe.drop(outliers.index)

    return dataframe

#-------------------------------------------------------------------------------
#LEITURA/CARREGAMENTO DAS IMAGENS
#-------------------------------------------------------------------------------

def Leituraimagens(imagem_path, ruido_path):
    """
    Objetivo: Fazer a leitura dos arquivos NIfTI de imagem e ruído, retornando seus dados e metadados.

    Entrada:
        - imagem_path (str): Caminho para o arquivo NIfTI da imagem.
        - ruido_path (str): Caminho para o arquivo NIfTI do ruído.

    Saída:
        - tuple: Uma tupla contendo os objetos e dados de imagem e ruído (imagem, ruido, imagem_data, imagem_aff, imagem_hdr, ruido_data, ruido_aff, ruido_hdr).
    """
    imagem = nib.load(imagem_path)
    ruido = nib.load(ruido_path)

    imagem_data = imagem.get_fdata()
    imagem_aff = imagem.affine
    imagem_hdr = imagem.header

    ruido_data = ruido.get_fdata()
    ruido_aff = ruido.affine
    ruido_hdr = ruido.header

    return imagem, ruido, imagem_data, imagem_aff, imagem_hdr, ruido_data, ruido_aff, ruido_hdr

#-------------------------------------------------------------------------------
#CABEÇALHO E DADOS SOBRE AS IMAGENS
#-------------------------------------------------------------------------------

def Dadosimagens(imagem, ruido, imagem_data, imagem_aff, imagem_hdr):
    """
    Objetivo: Exibir informações detalhadas sobre os dados de uma imagem, incluindo seu formato, tipo de dado, matriz de transformação afim e cabeçalho.

    Entrada:
        - imagem (nibabel.Nifti1Image): Objeto de imagem carregado.
        - ruido (nibabel.Nifti1Image): Objeto de ruído carregado.
        - imagem_data (numpy.ndarray): Dados brutos da imagem.
        - imagem_aff (numpy.ndarray): Matriz de transformação afim da imagem.
        - imagem_hdr (nibabel.spatialimages.Header): Cabeçalho da imagem.

    Saída:
        - A função não retorna nenhum valor. Ela imprime as informações diretamente no console.
    """

    print("------------------------FORMATO DAS IMAGENS----------------------------\n")
    print(imagem.shape, "\n")
    print("-----------------------TIPO DE DADO DA IMAGEM--------------------------\n")
    print(type(imagem_data), "\n")
    print("---------------------------MATRIX AFFIN--------------------------------\n")
    print(imagem_aff, "\n")
    print("----------------------------CABEÇALHO----------------------------------\n")
    print(imagem_hdr)

#-------------------------------------------------------------------------------
#PLOTAGEM DE TODOS OS CORTES DA IMAGEM OU RUÍDO
#-------------------------------------------------------------------------------

def plotagemimagens(imagem_data):
    """
    Objetivo: Plotar uma série de imagens em uma grade, aplicando normalização e adicionando uma barra de cores.

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D contendo os dados das imagens a serem plotadas.

    Saída:
        - A função não retorna nenhum valor. Ela exibe uma figura com as imagens plotadas.
    """
    x, y, z = imagem_data.shape
    a = min(x, y, z)

    linhas = a // 5
    colunas = math.ceil(a / linhas)

    fig, axs = plt.subplots(linhas, colunas, figsize=[10, 10])

    for idx in range(0, a, 1):
        imagem_data[:, :, idx] = 255 * imagem_data[:, :, idx] / np.max(imagem_data[:, :, idx])
        im = axs.flat[idx].imshow((imagem_data[:, :, idx]), cmap='gray')
        axs.flat[idx].axis('off')
        fig.colorbar(im, ax=axs.flat[idx])
        frame = imagem_data[:, :, idx]

    plt.tight_layout()
    plt.show()

#-------------------------------------------------------------------------------
#ALTERNATIVA DE VISUALIZAÇÃO DOS CORTES - VÍDEO
#-------------------------------------------------------------------------------

def videoimagens(imagem_data):
    """
    Objetivo: Gerar um vídeo a partir de uma série de imagens (slices) de um array 3D.

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D contendo os dados das imagens que serão usadas para criar o vídeo.

    Saída:
        - IPython.display.Video: Um objeto de vídeo que pode ser reproduzido diretamente em ambientes como Jupyter.
    """

    print(imagem_data.shape, type(imagem_data))
    print(f"Maior valor de cinza: {np.max(imagem_data):.1f} e menor valor de cinza: {np.min(imagem_data):.1f}")
    writer = FFMpegWriter(fps=10)
    fig, ax = plt.subplots()
    x, y, z = imagem_data.shape
    a = min(x, y, z)

    with writer.saving(fig, "imagem.mp4", 100):
        for idx in range(0, a, 1):
            frame = imagem_data[:,:,idx]
            plt.imshow(frame, cmap='gray')
            writer.grab_frame()
            plt.clf()

    plt.close(fig)

    return Video("imagem.mp4", embed=True)

#///////////////////////////////////////////////////////////////////////////////

#SEGUNDA ETAPA: AVALIAÇÃO DO RUÍDO DAS IMAGENS

#-------------------------------------------------------------------------------
#CÁLCULO DAS ESTATÍSTICAS DO RUÍDO GERAL
#-------------------------------------------------------------------------------

def perfilruidoimagem(ruido_data):
    """
    Objetivo: Analisar e visualizar o perfil de ruído de um conjunto de imagens, calculando estatísticas e plotando histograma, PDF e CDF.

    Entrada:
        - ruido_data (numpy.ndarray): Um array 3D contendo os dados de ruído.

    Saída:
        - tuple: Uma tupla contendo o desvio padrão (`std`), o valor médio (`mean`) e a imagem de ruído (`img_noise`).
        - Gráficos: Histograma, CDF e PDF do ruído.
    """

    x, y, z = ruido_data.shape
    a = min(x, y, z)
    img_noise = np.zeros((x, y))

    for i in range(0, a, 1):
        img_noise += 255 * ruido_data[:, :, i] / np.max(ruido_data[:, :, i])
    img_noise_hist = (img_noise / z).flatten()

    plt.figure(figsize=(20, 6))

    # Histograma do ruído
    plt.subplot(1, 3, 1)
    plt.hist(img_noise_hist, bins=256, color='blue')
    plt.title('Histograma do Ruído Geral')
    plt.xlabel('Valor')
    plt.ylabel('Frequência')

    # Cálculo de desvio padrão e média
    std = np.std(img_noise_hist)
    mean = np.mean(img_noise_hist)
    print(f"Desvio padrão do ruído geral: {std:.0f}")
    print(f"Valor médio do ruído geral: {mean:.0f}")

    # Função de densidade de probabilidade (PDF)
    plt.subplot(1, 3, 2)
    count, bins, ignored = plt.hist(img_noise_hist, bins=256, color='black', density=True)
    plt.title('Função Densidade de Probabilidade (PDF) do Ruído Geral')
    plt.xlabel('Valor')
    plt.ylabel('Densidade')

    # Função de densidade acumulada (CDF)
    plt.subplot(1, 3, 3)
    cdf = np.cumsum(count) * np.diff(bins)[0]
    plt.plot(bins[1:], cdf, 'g-', lw=2)
    plt.title('Função de Distribuição Acumulada (CDF) do Ruído Geral')
    plt.xlabel('Valor')
    plt.ylabel('Probabilidade Acumulada')

    plt.tight_layout()
    plt.show()

    return std, mean, img_noise

#-------------------------------------------------------------------------------
#SELEÇÃO DAS QUATRO ROIS QUE SE ENCONTRAM NOS CANTOS DAS IMAGENS
#-------------------------------------------------------------------------------

def noise_regions(I, zoom_region1, zoom_region2, zoom_region3, zoom_region4, zoom_width, plotar="False"):
    """
    Objetivo: Extrair e, opcionalmente, plotar quatro regiões de interesse (ROIs) de ruído de uma imagem, baseadas em coordenadas de canto.

    Entrada:
        - I (numpy.ndarray): A imagem de entrada.
        - zoom_region1 (tuple): Coordenadas (x, y) do canto superior esquerdo da região de zoom 1.
        - zoom_region2 (tuple): Coordenadas (x, y) do canto superior esquerdo da região de zoom 2.
        - zoom_region3 (tuple): Coordenadas (x, y) do canto superior esquerdo da região de zoom 3.
        - zoom_region4 (tuple): Coordenadas (x, y) do canto superior esquerdo da região de zoom 4.
        - zoom_width (int): Largura (e altura) das regiões de zoom.
        - plotar (str): Uma flag booleana que, se "True", plota a imagem com as ROIs e seus respectivos zooms.

    Saída:
        - tuple: Uma tupla contendo os arrays das quatro regiões de interesse (roi1, roi2, roi3, roi4).
    """

    I = 255 * I / np.max(I)

    if plotar:
        plt.figure(figsize=[40,5])

        plt.subplot(1,5,1)
        plt.imshow(I, cmap='gray', vmin=0)
        plt.title("Imagem")
        plt.colorbar(label="Intensities")
        plt.axis("off")
        ax = plt.gca()

        rect = patches.Rectangle(zoom_region1, zoom_width, zoom_width, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

        rect = patches.Rectangle(zoom_region2, zoom_width, zoom_width, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

        rect = patches.Rectangle(zoom_region3, zoom_width, zoom_width, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

        rect = patches.Rectangle(zoom_region4, zoom_width, zoom_width, linewidth=1, edgecolor='r', facecolor='none')
        ax.add_patch(rect)

    # Extrair e armazenar as ROIs como arrays
    roi1 = I[zoom_region1[1]:zoom_region1[1]+zoom_width, zoom_region1[0]:zoom_region1[0]+zoom_width]
    roi2 = I[zoom_region2[1]:zoom_region2[1]+zoom_width, zoom_region2[0]:zoom_region2[0]+zoom_width]
    roi3 = I[zoom_region3[1]:zoom_region3[1]+zoom_width, zoom_region3[0]:zoom_region3[0]+zoom_width]
    roi4 = I[zoom_region4[1]:zoom_region4[1]+zoom_width, zoom_region4[0]:zoom_region4[0]+zoom_width]

    if plotar:
        #Plotagem das ROIs referentes às regiões de ruído (Norma NEMA)
        plt.subplot(1,5,2)
        plt.imshow(roi1, cmap='gray', vmin=0, vmax=I.max())
        plt.title("Região 1")
        plt.colorbar(label="Intensities")
        plt.axis("off")

        plt.subplot(1,5,3)
        plt.imshow(roi2, cmap='gray', vmin=0, vmax=I.max())
        plt.title("Região 2")
        plt.colorbar(label="Intensities")
        plt.axis("off")

        plt.subplot(1,5,4)
        plt.imshow(roi3, cmap='gray', vmin=0, vmax=I.max())
        plt.title("Região 3")
        plt.colorbar(label="Intensities")
        plt.axis("off")

        plt.subplot(1,5,5)
        plt.imshow(roi4, cmap='gray', vmin=0, vmax=I.max())
        plt.title("Região 4")
        plt.colorbar(label="Intensities")
        plt.axis("off")

        plt.show()

    return roi1, roi2, roi3, roi4

#-------------------------------------------------------------------------------
#ANÁLISE ESTATÍSTICA DAS ROIS DA IMAGEM
#-------------------------------------------------------------------------------

def resumo_estatistica(roi1, roi2, roi3, roi4):
    """
    Objetivo: Calcular e resumir estatísticas descritivas (média e desvio padrão) para quatro regiões de interesse (ROIs) e para o conjunto de todas as ROIs.

    Entrada:
        - roi1, roi2, roi3, roi4 (numpy.ndarray): Arrays das regiões de interesse.

    Saída:
        - df_estatisticas (pd.DataFrame): DataFrame contendo as estatísticas calculadas.
        - roi (numpy.ndarray): Um array concatenado com os valores de todas as ROIs.
    """

    roi = np.concatenate([roi1.flatten(), roi2.flatten(), roi3.flatten(), roi4.flatten()])

    estatisticas = {
        'Media_roi1': np.mean(roi1),
        'Media_roi2': np.mean(roi2),
        'Media_roi3': np.mean(roi3),
        'Media_roi4': np.mean(roi4),
        'Std_roi1': np.std(roi1),
        'Std_roi2': np.std(roi2),
        'Std_roi3': np.std(roi3),
        'Std_roi4': np.std(roi4),
        'Media_geral': np.mean(roi),
        'Std_geral': np.std(roi)}

    df_estatisticas = pd.DataFrame([estatisticas])

    return df_estatisticas, roi

#-------------------------------------------------------------------------------
#TESTANDO SE O RUÍDO É ESTACIONÁRIO
#-------------------------------------------------------------------------------

from scipy.stats import chi2_contingency, rayleigh, norm, chi2

def teste_ruido_estacionario(roi1, roi2, roi3, roi4):
    """
    Objetivo: Realizar um teste qui-quadrado para verificar se o ruído nas quatro ROIs é estacionário (ou seja, se as distribuições de frequência são estatisticamente semelhantes).

    Entrada:
        - roi1, roi2, roi3, roi4 (numpy.ndarray): Arrays das regiões de interesse.

    Saída:
        - pd.DataFrame: Um DataFrame contendo o resultado do teste, indicando se o ruído é "Sim" ou "Não" estacionário.
    """
    df_estacionario = []

    #Encontrando o vetor do ruído contendo todo os valores das 4 rois:
    # Use a small constant to avoid zero expected frequencies
    dados = np.array([roi1, roi2, roi3, roi4]) + 1e-9
    chi2_stat, p_valor, graus_liberdade, freq_esperadas = chi2_contingency(dados)
    alpha = 0.05
    valor_critico = chi2.ppf(1 - alpha, graus_liberdade)

    i = 0
    #Interpretação
    if p_valor < 0.05:
        df_estacionario.append({"ESTACIONÁRIO": "Não" })
    else:
        df_estacionario.append({"ESTACIONÁRIO": "Sim"})

    return pd.DataFrame(df_estacionario)

#-------------------------------------------------------------------------------
#FILTRAGEM DAS IMAGENS
#-------------------------------------------------------------------------------

def filtragemimagens(imagem_data):
    """
    Objetivo: Aplicar um filtro Gaussiano a cada "slice" de um array 3D para reduzir ruído e suavizar as imagens.

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D contendo os dados das imagens a serem filtradas.

    Saída:
        - numpy.ndarray: Um array 3D com as mesmas dimensões, contendo as imagens processadas com o filtro Gaussiano.
    """

    img = np.zeros(imagem_data.shape)
    a = min(imagem_data.shape)

    for i in range(0, a, 1):
        img[:,:,i] = cv.GaussianBlur(imagem_data[:,:,i],(15,15),0)
        img[:,:,i] = 255 * img[:,:,i]/np.max(img[:,:,i])

    return img

#-------------------------------------------------------------------------------
#APLICAÇÃO DA MÁSCARA
#-------------------------------------------------------------------------------

def maskotsu(img):
    """
    Objetivo: Aplicar o método de Otsu para encontrar um limiar ótimo e gerar uma máscara binária a partir de uma imagem.

    Entrada:
        - img (numpy.ndarray): A imagem já filtrada (idealmente com um filtro Gaussiano) para a aplicação da binarização.

    Saída:
        - mask_otsu (numpy.ndarray): Um array binário (valores 0 e 1) que representa a máscara.
        - t_otsu (float): O valor do limiar encontrado pelo método de Otsu.
    """
    t_otsu = filters.threshold_otsu(img)
    mask_otsu = img>t_otsu

    return mask_otsu, t_otsu

#-------------------------------------------------------------------------------
#FUNÇÃO DE DETECÇÃO DOS CÍRCULOS
#-------------------------------------------------------------------------------

def detect_circles_in_slices(imagem_data):
    """
    Objetivo: Detectar círculos em cada "slice" de uma imagem 3D usando a transformada de Hough, visualizá-los e calcular seus diâmetros.

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D com os dados da imagem.

    Saída:
        - circulos (numpy.ndarray): Um array 3D com as imagens que possuem os círculos detectados e desenhados.
        - diametro (list): Uma lista contendo os diâmetros (em pixels) dos círculos detectados em cada slice.
    """
    images_with_circles = []
    num_slices = np.min(imagem_data.shape)
    diametro = []

    for j in range(num_slices):
        fatia = imagem_data[:, :, j]
        fatia_normalizada = (fatia - np.min(fatia)) / (np.max(fatia) - np.min(fatia))
        fatia_uint16 = (fatia_normalizada * 255).astype(np.uint16)

        buffer = io.BytesIO()
        plt.imsave(buffer, fatia_uint16, format='png', cmap='gray')
        buffer.seek(0)
        img = np.array(Image.open(buffer))

        img = cv.GaussianBlur(img, (5, 5), 0)
        img_gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)
        circles = cv.HoughCircles(img_gray, cv.HOUGH_GRADIENT, 1, 50, param1=100, param2=50, minRadius=0, maxRadius=0)

        if circles is not None:
            circles = np.uint16(np.around(circles))
            if len(circles[0, :]) == 1:
                i = circles[0, 0]
                cv.circle(img, (i[0], i[1]), i[2], (0, 255, 0), 2)
                cv.circle(img, (i[0], i[1]), 1, (0, 0, 255), 3)
                images_with_circles.append(img)
                diametro.append(2*i[2])

    images_with_circles = np.array(images_with_circles)
    circulos = np.array(images_with_circles[:,:,:,0])
    circulos = np.transpose(circulos, (1, 2, 0))

    return circulos, diametro

#-------------------------------------------------------------------------------
#FUNÇÃO DE CÁLCULO DA DISTORÇÃO DO DIÂMETRO
#-------------------------------------------------------------------------------

def distorsao_diametro(diametro, FOV, diametro_real, matrix_dim):
    """
    Objetivo: Calcular a distorção percentual do diâmetro de um objeto com base no FOV, dimensão da matriz e diâmetro real.

    Entrada:
        - diametro (list): Uma lista de diâmetros (em pixels) dos objetos detectados.
        - FOV (int): O campo de visão em milímetros (mm).
        - diametro_real (int): O diâmetro real do objeto em milímetros (mm).
        - matrix_dim (int): A dimensão da matriz em pixels.

    Saída:
        - pd_diametro (pd.DataFrame): Um DataFrame contendo as métricas de distorção calculadas.
    """

    tabela_diametro = []

    FOV = 50 #mm
    matrix = 256 #pixels
    D_real = 25 #mm
    size_pixel = FOV/matrix
    D_medido = np.zeros(len(diametro))

    for j in range(0, len(diametro), 1):
        D_medido[j] = size_pixel*diametro[j]

    print("=================DISTORÇÃO DO MAIOR DIÂMETRO===========================")
    print("Tamanho do pixel:", size_pixel)
    print(f"FOV: {FOV:.2f} mm")
    print(f"Diâmetro Real: {D_real:.2f} mm")
    print(f"Dimensão do pixel: {size_pixel:.2f} mm/pixels")
    print(f"Diâmetro máximo calculado =  {np.max(D_medido):.2f} mm")
    geometry_raio = abs((np.max(D_medido)-D_real)/np.max(D_medido))*100
    print(f"Porcentagem de Distorção do diâmetro =  {geometry_raio:.2f} %")
    print("=======================================================================")

    tabela_diametro.append({
        'tamanho_pixel_mm': size_pixel,
        'FOV_mm': FOV,
        'diametro_real_mm': D_real,
        'diametro_max_calculado_mm': np.max(D_medido),
        'distorcao_diametro_percentual_%': geometry_raio
    })

    pd_diametro = pd.DataFrame(tabela_diametro)

    return pd_diametro

#-------------------------------------------------------------------------------
#FUNÇÃO PARA CÁLCULO DA RELAÇÃO SINAL RUÍDO
#-------------------------------------------------------------------------------

def SNR(imagem_data, mostrar_plots=False):
    """
    Objetivo: Calcular a relação sinal-ruído (SNR) para cada corte de uma imagem 3D, usando o método do sinal na MROI e o desvio padrão do ruído.

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D com os dados da imagem.
        - mostrar_plots (bool): Uma flag para indicar se devem ser plotadas as máscaras e as MROIs.

    Saída:
        - df_snr (pd.DataFrame): Um DataFrame contendo a SNR, SNR em dB, média e o limiar para cada corte.
    """
    resultados = []

    for i in range(imagem_data.shape[2]):
        imagem_snr = imagem_data[:,:,i]
        imagem_snr = 255 * imagem_snr/np.max(imagem_snr) if np.max(imagem_snr) > 0 else imagem_snr
        mask_otsu, t_otsu = maskotsu(imagem_snr)
        S_MROI = mask_otsu * imagem_snr

        mean = np.mean(imagem_snr)
        std = np.std(imagem_snr)

        if mostrar_plots:
            plt.figure(figsize=(20, 6))

            plt.subplot(1,2,1)
            plt.imshow(mask_otsu, cmap='gray')
            plt.title(f"Máscara Binária - Corte {i+1}")
            plt.colorbar()

            plt.subplot(1,2,2)
            plt.imshow(S_MROI, cmap='gray')
            plt.title(f"MROI - Corte {i+1}")
            plt.colorbar()
            plt.show()

        # Média dos pixels da MROI
        sinal_mroi = S_MROI[S_MROI > 0]
        S = np.mean(sinal_mroi) if len(sinal_mroi) > 0 else 0

        # Cálculo do valor da "Image Noise"
        image_noise = std / 0.66

        SNR = S/image_noise if image_noise > 0 else 0
        SNR_db = 20*np.log10(SNR) if SNR > 0 else 0

        # Armazenar resultados
        resultados.append({
            'Corte': i + 1,
            'Média': S,
            'Image_Noise': image_noise,
            'SNR': SNR,
            'SNR_db': SNR_db,
            'Limiar': t_otsu
        })

    df_snr = pd.DataFrame(resultados)
    return df_snr

#-------------------------------------------------------------------------------
#FUNÇÃO PARA CALCULO DO CONTRASTE E DA HOMOGÊNIEDADE
#-------------------------------------------------------------------------------

from skimage.feature import graycomatrix, graycoprops

def calc_homogenidade_contraste(imagem_data):
    """
    Objetivo: Calcular os atributos de homogeneidade e contraste de cada "slice" de uma imagem 3D usando a Matriz de Co-ocorrência de Níveis de Cinza (GLCM).

    Entrada:
        - imagem_data (numpy.ndarray): Um array 3D com os dados da imagem.

    Saída:
        - df (pd.DataFrame): Um DataFrame contendo os valores de homogeneidade e contraste para cada corte.
    """

    homogeneity = []
    contrast = []

    for i in range(0, imagem_data.shape[2], 1):
        image = imagem_data[:, :, i]
        image_normalized = (image - image.min()) / (image.max() - image.min())
        image_uint8 = (image_normalized * 255).astype(np.uint8)
        GLCM = graycomatrix(image_uint8, [1], [0, np.pi/4, np.pi/2, 3*np.pi/4])
        homogeneity.append(graycoprops(GLCM, 'homogeneity')[0, 0])
        contrast.append(graycoprops(GLCM, 'contrast')[0, 0])

    df = pd.DataFrame({'homogeneity': homogeneity, 'contrast': contrast})

    return df

#-------------------------------------------------------------------------------
#CÁLCULO DOS EIXOS E DA ESFERICIDADE
#-------------------------------------------------------------------------------

from skimage.measure import label, regionprops, regionprops_table

def esfericidade(mask_otsu, Plotar=False):
    """
    Objetivo: Calcular a esfericidade (relação entre os eixos maior e menor) de objetos em uma máscara binária, e, opcionalmente, plotar os eixos.

    Entrada:
        - mask_otsu (numpy.ndarray): Um array binário 3D que representa a máscara de objetos.
        - Plotar (bool): Uma flag para indicar se os eixos e o centroide devem ser plotados sobre a imagem.

    Saída:
        - df_esfericidade (pd.DataFrame): Um DataFrame contendo o comprimento dos eixos maior e menor, e o valor da esfericidade para cada objeto detectado.
    """

    propriedades = []
    esfericidade_dict = {}

    for i in range(mask_otsu.shape[2]):

        image = mask_otsu[:, :, i]

        label_img = label(image)
        regions = regionprops(label_img)

        if Plotar:
            fig, ax = plt.subplots()
            ax.imshow(image, cmap=plt.cm.gray)

            for props in regions:
                y0, x0 = props.centroid
                orientation = props.orientation
                x1 = x0 + math.cos(orientation) * 0.5 * props.axis_minor_length
                y1 = y0 - math.sin(orientation) * 0.5 * props.axis_minor_length
                x2 = x0 - math.sin(orientation) * 0.5 * props.axis_major_length
                y2 = y0 - math.cos(orientation) * 0.5 * props.axis_major_length

                ax.plot((x0, x1), (y0, y1), '-r', linewidth=2.5)
                ax.plot((x0, x2), (y0, y2), '-r', linewidth=2.5)
                ax.plot(x0, y0, '.g', markersize=15)

                minr, minc, maxr, maxc = props.bbox
                bx = (minc, maxc, maxc, minc, minc)
                by = (minr, minr, maxr, maxr, minr)
                ax.plot(bx, by, '-b', linewidth=2.5)

            ax.axis((0, image.shape[1], image.shape[0], 0))
            plt.show()

        props = regionprops_table(
            label_img,
            properties=('centroid', 'orientation', 'axis_major_length', 'axis_minor_length'),
        )

        df_slice = pd.DataFrame(props)
        df_slice['slice'] = i
        propriedades.append(df_slice)

    propriedades_finais = pd.concat(propriedades, ignore_index=True)

    esfericidade_dict["Esfericidade"] = (propriedades_finais["axis_minor_length"] / propriedades_finais["axis_major_length"]) * 100
    df_esfericidade = pd.DataFrame(esfericidade_dict)
    df_esfericidade = pd.concat([propriedades_finais[["axis_major_length", "axis_minor_length"]], df_esfericidade], axis=1)


    return df_esfericidade

#-------------------------------------------------------------------------------
#CÁLCULO DO CV
#-------------------------------------------------------------------------------

#Calculo do coeficiente de variação para cada um dos cortes:
def calc_CV(mask_otsu,imagem_data):
    """
    Objetivo: Calcular o Coeficiente de Variação (CV) para cada corte de imagem, com base nos valores de pixels dentro de uma máscara.

    Entrada:
        - mask_otsu (numpy.ndarray): Um array 3D com a máscara binária.
        - imagem_data (numpy.ndarray): Um array 3D com os dados de imagem originais.

    saída:
        - df (pd.DataFrame): Um DataFrame contendo o valor do Coeficiente de Variação (CV) para cada corte.
    """

    image_h = mask_otsu*imagem_data
    coeficiente_variacao = []
    df = pd.DataFrame()

    for i in range(image_h.shape[2]):

        image_homogenidade = image_h[:,:,i]
        soma = 0
        n = 0


        for i in range(image_h.shape[0]):
            for j in range(image_h.shape[1]):
                if image_homogenidade[i,j] > 0:
                    soma += image_homogenidade[i,j]
                    n += 1

        mean = soma / n
        image_homogenidade = np.array(image_homogenidade)
        image_homogenidade_nor = 255 * (image_homogenidade - image_homogenidade.min()) / (image_homogenidade.max() - image_homogenidade.min())

        for i in range(image_h.shape[0]):
            for j in range(image_h.shape[1]):
                if image_homogenidade[i,j] == 0:
                    image_homogenidade[i,j] = mean

        np.std(image_homogenidade)
        CV = 100*(np.std(image_homogenidade)/mean)
        coeficiente_variacao.append(CV)

    df["CV"] = pd.DataFrame(coeficiente_variacao)

    return df

#-------------------------------------------------------------------------------
#MONTANDO DATAFRAME COM OS RESULTADOS
#-------------------------------------------------------------------------------

def medicoes_totais(df_snr, df_h_c, df, df_esfericidade, df_s):
    """
    Objetivo: Concatenar e processar DataFrames de diferentes métricas (SNR, CV, esfericidade, etc.) em um único DataFrame final, removendo outliers e filtrando dados.

    Entrada:
        - df_snr (pd.DataFrame): DataFrame com os resultados do SNR.
        - df (pd.DataFrame): DataFrame com os resultados do Coeficiente de Variação.
        - df_esfericidade (pd.DataFrame): DataFrame com os resultados da esfericidade.
        - df_s (pd.DataFrame): DataFrame com os resultados do teste de ruído estacionário.

    Saída:
        - df_final (pd.DataFrame): O DataFrame final consolidado com todas as métricas, limpo de outliers.
    """
    df_final = pd.concat([df_snr, df_h_c, df, df_esfericidade, df_s], axis=1)
    df_final = df_final.dropna()
    df_final = remove_outliers(df_final, "axis_major_length")
    df_final = remove_outliers(df_final, "axis_minor_length")
    df_final = remove_outliers(df_final, "Esfericidade")
    df_final = df_final[df_final['ESTACIONÁRIO'] != 0]
    df_final = df_final.round(2)

    return df_final

#-------------------------------------------------------------------------------
#TESTE DE DISTRIBUIÇÃO
#-------------------------------------------------------------------------------

from scipy.stats import chi2_contingency, rayleigh, norm, chi2

def teste_ruido_estacionario(roi1, roi2, roi3, roi4):
    """
    Objetivo: Realizar um teste qui-quadrado para verificar se o ruído nas quatro ROIs é estacionário (ou seja, se as distribuições de frequência são estatisticamente semelhantes).

    Entrada:
        - roi1, roi2, roi3, roi4 (numpy.ndarray): Arrays das regiões de interesse.

    Saída:
        - pd.DataFrame: Um DataFrame contendo o resultado do teste, indicando se o ruído é "Sim" ou "Não" estacionário.
    """

    df_estacionario = []

    #Encontrando o vetor do ruído contendo todo os valores das 4 rois:
    # Use a small constant to avoid zero expected frequencies
    dados = np.array([roi1, roi2, roi3, roi4]) + 1e-9
    chi2_stat, p_valor, graus_liberdade, freq_esperadas = chi2_contingency(dados)
    alpha = 0.05
    valor_critico = chi2.ppf(1 - alpha, graus_liberdade)

    i = 0
    #Interpretação
    if p_valor < 0.05:
        df_estacionario.append({"ESTACIONÁRIO": "Não" })
    else:
        df_estacionario.append({"ESTACIONÁRIO": "Sim"})

    return pd.DataFrame(df_estacionario)

#-------------------------------------------------------------------------------
#SALVANDO OS RESULTADOS DE FORMA ORGANIZADA PARA AVALIAÇÃO
#-------------------------------------------------------------------------------

def pipeline_completo(imagem_path, ruido_path, FOV=50, diametro_real=25, matrix_dim=256,
                      dim_roi=50, mostrar_plots=True, gerar_videos=True):
    """
    Objetivo: Executar um pipeline completo de análise de qualidade de imagens de ressonância magnética, desde a leitura dos dados até o cálculo e compilação de métricas de qualidade (SNR, distorção, esfericidade, etc.).

    Entrada:
        - imagem_path (str): Caminho para o arquivo NIfTI da imagem.
        - ruido_path (str): Caminho para o arquivo NIfTI do ruído.
        - FOV (int): O campo de visão em milímetros.
        - diametro_real (int): O diâmetro real do objeto em milímetros.
        - matrix_dim (int): A dimensão da matriz em pixels.
        - dim_roi (int): Dimensão das ROIs de ruído.
        - mostrar_plots (bool): Flag para exibir gráficos intermediários.
        - gerar_videos (bool): Flag para gerar vídeos dos passos de processamento.

    Saídas:
        - df_final (pd.DataFrame): DataFrame final com todas as métricas compiladas e limpas.
        - pd_diametro (pd.DataFrame): DataFrame com os resultados de distorção do diâmetro.
    """

    print("="*80)
    print("PIPELINE COMPLETO - ANÁLISE DE QUALIDADE DE IMAGENS MRI")
    print("="*80)

    #---------------------------------------------------------------------------

    #ETAPA 1: LEITURA DAS IMAGENS
    print("ETAPA 1: LEITURA DAS IMAGENS")
    imagem, ruido, imagem_data, imagem_aff, imagem_hdr, ruido_data, ruido_aff, ruido_hdr = Leituraimagens(imagem_path, ruido_path)

    print("DADOS DAS IMAGENS:")
    Dadosimagens(imagem, ruido, imagem_data, imagem_aff, imagem_hdr)

    #---------------------------------------------------------------------------

    #ETAPA 2: VISUALIZAÇÃO DAS IMAGENS
    print("="*80)
    if mostrar_plots or gerar_videos:
        print("ETAPA 2: VISUALIZAÇÃO DAS IMAGENS")

        if mostrar_plots:
            plotagemimagens(imagem_data)

        if gerar_videos:
            video_original = videoimagens(imagem_data)
    else:
        print("="*80)
        print("ETAPA 2 PULADA: VISUALIZAÇÃO DAS IMAGENS")

    #---------------------------------------------------------------------------

    #ETAPA 3: ANÁLISE DO RUÍDO
    print("="*80)
    print("ETAPA 3: ANÁLISE DO RUÍDO")
    std_ruido, mean_ruido, img_noise = perfilruidoimagem(ruido_data)

    dim = 50
    todas_df = []
    df_s = []

    for i in np.arange(0,imagem_data.shape[2],1):
        roi1, roi2, roi3, roi4 = noise_regions(imagem_data[:,:,i], [0,0],[255-dim,0],[0,255-dim],[255-dim,255-dim], dim, plotar=False)
        df_estatisticas, roi = resumo_estatistica(roi1, roi2, roi3, roi4)
        todas_df.append(df_estatisticas)
        df_estacionario = teste_ruido_estacionario(roi1, roi2, roi3, roi4)
        df_s.append(df_estacionario)

    df_roi = pd.concat(todas_df, ignore_index=True)
    df_s = pd.concat(df_s, ignore_index=True)

    #---------------------------------------------------------------------------

    #ETAPA 4: FILTRAGEM DAS IMAGENS
    print("="*80)
    print("ETAPA 4: FILTRAGEM DAS IMAGENS - Filtro Gaussinano")
    img_filtrada = filtragemimagens(imagem_data)

    if gerar_videos:
        print("Vídeo das imagens filtradas")
        video_filtrado = videoimagens(img_filtrada)
        video_filtrado

    #---------------------------------------------------------------------------

    #ETAPA 5: CRIAÇÃO DE MÁSCARAS BINÁRIAS
    print("="*80)
    print("ETAPA 5: MÁSCARAS BINÁRIAS - Método de Otsu")
    mask_otsu, t_otsu = maskotsu(img_filtrada)

    if gerar_videos:
        print("Vídeo das máscaras")
        video_mask = videoimagens(mask_otsu.astype(float))
        video_mask

    #---------------------------------------------------------------------------

    #ETAPA 6: DETECÇÃO DE CÍRCULOS
    print("="*80)
    print("ETAPA 6: DETECTANDO CÍRCULOS - Transformada de Hough")
    circulos, diametros = detect_circles_in_slices(imagem_data)

    if gerar_videos and len(diametros) > 0:
        print("Vídeo da detecção dos círculos")
        video_circulos = videoimagens(circulos)
        video_circulos

    #---------------------------------------------------------------------------

    #ETAPA 7: CÁLCULO DE MÉTRICAS
    print("="*80)
    print("ETAPA 7: CALCULANDO MÉTRICAS")

    # 7.1 - Distorção do maior diâmetro
    print("1) Distorção do maior diâmetro")
    pd_diametro = distorsao_diametro(diametros, 50, 25, 256)

    # 7.2 - SNR
    print("2) SNR")
    df_snr = SNR(imagem_data, mostrar_plots=False)

    # 7.3 - Homogeneidade e Contraste
    print("3) Homogeneidade e Contraste")
    df_h_c = calc_homogenidade_contraste(imagem_data)

    # 7.4 - Filtragem e Limiarização com Otsu
    print("4) Homogeneidade e Contraste")
    circulos = filtragemimagens(circulos)
    mask_circulos, t_otsu_circulos = maskotsu(circulos)

    # 7.5 - Esfericidade
    print("5) Esfericidade")
    df_esfericidade = esfericidade(mask_otsu)
    df_esfericidade

    # 7.6 - Coeficiente de Variação
    print("6) Coeficiente de Variação")
    df = calc_CV(mask_otsu,imagem_data)

    #ETAPA 8: COMPILAÇÃO DOS RESULTADOS
    print("="*80)
    print("ETAPA 8: RESULTADOS FINAIS")

    df_final = medicoes_totais(df_snr, df_h_c, df, df_esfericidade, df_s)
    df_final = df_final.drop(columns=["axis_major_length", "axis_minor_length"])

    print("Tabela com todas as métricas")
    print(pd_diametro)
    df_final
    print("="*80)
    # Salvando os resultados
    df_final.to_csv("resultados_finais.csv", index=False)
    pd_diametro.to_csv("distorcao_diametro.csv", index=False)
    print("\nResultados salvos em 'resultados_finais.csv' e 'distorcao_diametro.csv'.")

    return df_final, pd_diametro